{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 18 October 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.4 in Textbook: Classifying movie reviews with IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# loading the IMDB dataset\n",
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[24999])\n",
    "# each number has a corresponding word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "# this is an array of 25,000 1 dimensional arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[24999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2. Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data before building the model\n",
    "\n",
    "#issue: you cannot fit the integer values into the NN... need to factorize\n",
    "# want to fit into binary format (0s and 1s)... transform 1D to 2D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# def vectorize_sequences(sequences, dimension=10000):\n",
    "#     results = np.zeros((len(sequences), dimension)) # Creates an all-zero matrix of shape\n",
    "#     for i, sequence in enumerate(sequence):\n",
    "#         results[i, sequence] = 1. # Set specific indices of results[i] to 1s\n",
    "#     return results\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.0\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 1. 0. 1.]\n",
      " [1. 0. 1. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sequences = [\n",
    "    [1, 3, 5], # first sequence\n",
    "    [0, 2, 3], # second sequence\n",
    "    [2, 4] # third sequence\n",
    "]\n",
    "\n",
    "# vectorizing the example sequences\n",
    "vectorized_data = vectorize_sequences(sequences, dimension=6)\n",
    "\n",
    "print(vectorized_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n",
      "[0. 1. 1. ... 0. 0. 0.]\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorize_sequences(train_data)\n",
    "X_test = vectorize_sequences(test_data)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[24999])\n",
    "\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ntlmp\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Validating your approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set apart 1000 samples in the training data to use as a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "(15000, 10000)\n",
      "[1. 0. 0. ... 1. 0. 0.]\n",
      "[0. 0. 0. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "X_val = X_train[:10000] # usually need to use resampling without replacement\n",
    "print(X_val.shape)\n",
    "\n",
    "partial_X_train = X_train[10000:]\n",
    "print(partial_X_train.shape)\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(y_val)\n",
    "print(partial_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.6668 - loss: 0.6177 - val_accuracy: 0.8306 - val_loss: 0.4416\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8865 - loss: 0.3690 - val_accuracy: 0.8787 - val_loss: 0.3277\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9195 - loss: 0.2566 - val_accuracy: 0.8880 - val_loss: 0.2858\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9351 - loss: 0.2049 - val_accuracy: 0.8877 - val_loss: 0.2745\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9429 - loss: 0.1737 - val_accuracy: 0.8867 - val_loss: 0.2742\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9583 - loss: 0.1369 - val_accuracy: 0.8853 - val_loss: 0.2815\n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9672 - loss: 0.1178 - val_accuracy: 0.8847 - val_loss: 0.2907\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9715 - loss: 0.1024 - val_accuracy: 0.8774 - val_loss: 0.3089\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0856 - val_accuracy: 0.8798 - val_loss: 0.3377\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9819 - loss: 0.0728 - val_accuracy: 0.8780 - val_loss: 0.3527\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9851 - loss: 0.0613 - val_accuracy: 0.8749 - val_loss: 0.3785\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0498 - val_accuracy: 0.8771 - val_loss: 0.3750\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9918 - loss: 0.0428 - val_accuracy: 0.8774 - val_loss: 0.3949\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9935 - loss: 0.0345 - val_accuracy: 0.8757 - val_loss: 0.4131\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9954 - loss: 0.0275 - val_accuracy: 0.8736 - val_loss: 0.4347\n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0231 - val_accuracy: 0.8719 - val_loss: 0.4576\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0180 - val_accuracy: 0.8713 - val_loss: 0.4833\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0167 - val_accuracy: 0.8709 - val_loss: 0.5048\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9992 - loss: 0.0125 - val_accuracy: 0.8694 - val_loss: 0.5229\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9991 - loss: 0.0105 - val_accuracy: 0.8687 - val_loss: 0.5413\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(x=partial_X_train,\n",
    "                    y=partial_y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=512, # 2 to the power of something\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_dict = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x224ea342fe0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_values = hist_dict['loss']\n",
    "val_loss_values = hist_dict['val_loss']\n",
    "\n",
    "eps = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(eps, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(eps, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.7111 - loss: 0.5842 - val_accuracy: 0.8695 - val_loss: 0.3748\n",
      "Epoch 2/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8910 - loss: 0.3288 - val_accuracy: 0.8730 - val_loss: 0.3218\n",
      "Epoch 3/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9244 - loss: 0.2375 - val_accuracy: 0.8879 - val_loss: 0.2819\n",
      "Epoch 4/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9414 - loss: 0.1857 - val_accuracy: 0.8908 - val_loss: 0.2737\n",
      "Epoch 5/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9511 - loss: 0.1544 - val_accuracy: 0.8836 - val_loss: 0.2869\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8755 - loss: 0.3073\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training the model\n",
    "model.fit(x=partial_X_train,\n",
    "          y=partial_y_train,\n",
    "          epochs=5,\n",
    "          batch_size=512, # 2 to the power of something\n",
    "          validation_data=(X_val, y_val))\n",
    "\n",
    "# saving results\n",
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3078062832355499, 0.8758400082588196]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Classifying newswires: a multiclass classificaiton example\n",
    "#### 3.5.1 The Reuters datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,)\n",
      "(8982,)\n",
      "(2246,)\n",
      "(2246,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n",
      "31\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_data[10])\n",
    "\n",
    "print(len(train_data[10]))\n",
    "\n",
    "print(train_labels[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 10000)\n",
      "(2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorize_sequences(train_data)\n",
    "X_test = vectorize_sequences(test_data)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ntlmp\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax')) # regression\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Validating your approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,)\n",
      "(8982, 10000)\n"
     ]
    }
   ],
   "source": [
    "v_train_labels = vectorize_sequences(train_labels)\n",
    "v_test_labels = vectorize_sequences(test_labels)\n",
    "\n",
    "print(train_labels.shape)\n",
    "print(v_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 46)\n",
      "(8982, 46)\n"
     ]
    }
   ],
   "source": [
    "# alternative way to vectorization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(one_hot_train_labels.shape)\n",
    "print(one_hot_train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set aside 1000 validation samples\n",
    "X_val = X_train[:1000]\n",
    "partial_X_train = X_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.3748 - loss: 3.1647 - val_accuracy: 0.6220 - val_loss: 1.8390\n",
      "Epoch 2/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6629 - loss: 1.6694 - val_accuracy: 0.6740 - val_loss: 1.4117\n",
      "Epoch 3/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7178 - loss: 1.2590 - val_accuracy: 0.7300 - val_loss: 1.2112\n",
      "Epoch 4/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7786 - loss: 1.0321 - val_accuracy: 0.7590 - val_loss: 1.0787\n",
      "Epoch 5/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8197 - loss: 0.8461 - val_accuracy: 0.7850 - val_loss: 0.9881\n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8483 - loss: 0.7102 - val_accuracy: 0.8050 - val_loss: 0.9289\n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8810 - loss: 0.5770 - val_accuracy: 0.8060 - val_loss: 0.8896\n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9001 - loss: 0.4848 - val_accuracy: 0.8070 - val_loss: 0.8648\n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9147 - loss: 0.4170 - val_accuracy: 0.8090 - val_loss: 0.8889\n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9261 - loss: 0.3535 - val_accuracy: 0.8120 - val_loss: 0.8424\n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9337 - loss: 0.3094 - val_accuracy: 0.8120 - val_loss: 0.8353\n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9410 - loss: 0.2718 - val_accuracy: 0.8120 - val_loss: 0.8511\n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9486 - loss: 0.2332 - val_accuracy: 0.7990 - val_loss: 0.8899\n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9527 - loss: 0.1999 - val_accuracy: 0.7940 - val_loss: 0.9035\n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9548 - loss: 0.1791 - val_accuracy: 0.8070 - val_loss: 0.9053\n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9556 - loss: 0.1611 - val_accuracy: 0.8140 - val_loss: 0.8971\n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1589 - val_accuracy: 0.7930 - val_loss: 0.9491\n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9572 - loss: 0.1496 - val_accuracy: 0.8140 - val_loss: 0.9004\n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9606 - loss: 0.1324 - val_accuracy: 0.8060 - val_loss: 0.9676\n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9631 - loss: 0.1197 - val_accuracy: 0.8060 - val_loss: 0.9546\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_X_train, partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=512,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist_dict = history.history\n",
    "loss_values = hist_dict['loss']\n",
    "val_loss_values = hist_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss') # 'bo' means blue dot\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss') # 'b' means solid blue line\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# # Setting the x-ticks to integers and adding breaks at every 5 epochs\n",
    "# plt.xticks(range(0, len(loss_values) + 1, 5))  # Adjust the step size to 5\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.3195 - loss: 3.2715 - val_accuracy: 0.6100 - val_loss: 1.9326\n",
      "Epoch 2/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6550 - loss: 1.7481 - val_accuracy: 0.7000 - val_loss: 1.4167\n",
      "Epoch 3/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7324 - loss: 1.2578 - val_accuracy: 0.7300 - val_loss: 1.2186\n",
      "Epoch 4/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7838 - loss: 1.0200 - val_accuracy: 0.7590 - val_loss: 1.0990\n",
      "Epoch 5/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8168 - loss: 0.8627 - val_accuracy: 0.7660 - val_loss: 1.0668\n",
      "Epoch 6/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8473 - loss: 0.7158 - val_accuracy: 0.7880 - val_loss: 0.9866\n",
      "Epoch 7/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.5893 - val_accuracy: 0.8070 - val_loss: 0.9169\n",
      "Epoch 8/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9026 - loss: 0.4805 - val_accuracy: 0.8080 - val_loss: 0.8971\n",
      "Epoch 9/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9159 - loss: 0.4023 - val_accuracy: 0.8200 - val_loss: 0.8732\n",
      "Epoch 10/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9281 - loss: 0.3594 - val_accuracy: 0.8310 - val_loss: 0.8659\n",
      "Epoch 11/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9361 - loss: 0.3044 - val_accuracy: 0.8260 - val_loss: 0.8526\n",
      "Epoch 12/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9390 - loss: 0.2651 - val_accuracy: 0.8170 - val_loss: 0.8579\n",
      "Epoch 13/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9459 - loss: 0.2287 - val_accuracy: 0.8140 - val_loss: 0.8788\n",
      "Epoch 14/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9503 - loss: 0.2104 - val_accuracy: 0.8240 - val_loss: 0.8673\n",
      "Epoch 15/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9548 - loss: 0.1765 - val_accuracy: 0.8160 - val_loss: 0.8948\n",
      "Epoch 16/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9522 - loss: 0.1764 - val_accuracy: 0.8130 - val_loss: 0.8943\n",
      "Epoch 17/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9605 - loss: 0.1529 - val_accuracy: 0.7990 - val_loss: 0.9392\n",
      "Epoch 18/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9559 - loss: 0.1549 - val_accuracy: 0.8210 - val_loss: 0.9110\n",
      "Epoch 19/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9570 - loss: 0.1429 - val_accuracy: 0.8120 - val_loss: 0.9578\n",
      "Epoch 20/20\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9560 - loss: 0.1432 - val_accuracy: 0.8110 - val_loss: 0.9357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x224e774af20>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax')) # regression\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_X_train, partial_y_train,\n",
    "          epochs=20,\n",
    "          batch_size=512,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.9727\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0329065322875977, 0.7920747995376587]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "(46,)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(predictions[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 1\n",
      "True was: 10\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "print(\"predicted:\", np.argmax(predictions[i]))\n",
    "print(\"True was:\", test_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.6 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  ...  Fine Aggregate  Age  Strength\n",
       "0   540.0                 0.0      0.0  ...           676.0   28     79.99\n",
       "1   540.0                 0.0      0.0  ...           676.0   28     61.89\n",
       "2   332.5               142.5      0.0  ...           594.0  270     40.27\n",
       "3   332.5               142.5      0.0  ...           594.0  365     41.05\n",
       "4   198.6               132.4      0.0  ...           825.5  360     44.30\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "concrete_data = pd.read_csv(\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv\")\n",
    "\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 9)\n"
     ]
    }
   ],
   "source": [
    "print(concrete_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag  ...          Age     Strength\n",
       "count  1030.000000         1030.000000  ...  1030.000000  1030.000000\n",
       "mean    281.167864           73.895825  ...    45.662136    35.817961\n",
       "std     104.506364           86.279342  ...    63.169912    16.705742\n",
       "min     102.000000            0.000000  ...     1.000000     2.330000\n",
       "25%     192.375000            0.000000  ...     7.000000    23.710000\n",
       "50%     272.900000           22.000000  ...    28.000000    34.445000\n",
       "75%     350.000000          142.950000  ...    56.000000    46.135000\n",
       "max     540.000000          359.400000  ...   365.000000    82.600000\n",
       "\n",
       "[8 rows x 9 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# descriptive statistics\n",
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
      "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# split data into predictor variables and target\n",
    "concrete_data_columns = concrete_data.columns\n",
    "print(concrete_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030,)\n"
     ]
    }
   ],
   "source": [
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']]\n",
    "# predictors = concrete_data.drop(columns='Strength')\n",
    "\n",
    "target = concrete_data['Strength']\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag  ...  Fine Aggregate       Age\n",
       "0  2.476712           -0.856472  ...       -1.217079 -0.279597\n",
       "1  2.476712           -0.856472  ...       -1.217079 -0.279597\n",
       "2  0.491187            0.795140  ...       -2.239829  3.551340\n",
       "3  0.491187            0.795140  ...       -2.239829  5.055221\n",
       "4 -0.790075            0.678079  ...        0.647569  4.976069\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize the data\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# build NN\n",
    "n_cols = predictors_norm.shape[1] # rows, cols = _.shape\n",
    "# define regrssion model\n",
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape=(n_cols, )))\n",
    "    model.add(Dense(50, activation = 'relu'))\n",
    "    model.add(Dense(1)) #, activation = 'linear')\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ntlmp\\AppData\\Local\\R-MINI~1\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 1652.2411 - val_loss: 1148.6884\n",
      "Epoch 2/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1582.8376 - val_loss: 1032.0109\n",
      "Epoch 3/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1442.4752 - val_loss: 851.5246\n",
      "Epoch 4/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1078.6467 - val_loss: 618.7076\n",
      "Epoch 5/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 770.1453 - val_loss: 379.6068\n",
      "Epoch 6/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 436.3485 - val_loss: 230.7947\n",
      "Epoch 7/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 257.0499 - val_loss: 175.3872\n",
      "Epoch 8/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 234.4537 - val_loss: 164.7265\n",
      "Epoch 9/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 236.5119 - val_loss: 159.7236\n",
      "Epoch 10/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 204.9452 - val_loss: 155.6051\n",
      "Epoch 11/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 203.4469 - val_loss: 149.8772\n",
      "Epoch 12/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 175.9047 - val_loss: 146.9109\n",
      "Epoch 13/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 187.7452 - val_loss: 141.5517\n",
      "Epoch 14/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 190.2405 - val_loss: 137.8046\n",
      "Epoch 15/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 179.5724 - val_loss: 136.2318\n",
      "Epoch 16/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 162.5893 - val_loss: 133.1978\n",
      "Epoch 17/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 157.7675 - val_loss: 131.6837\n",
      "Epoch 18/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 151.3452 - val_loss: 133.5380\n",
      "Epoch 19/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 160.9584 - val_loss: 131.0304\n",
      "Epoch 20/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 156.9333 - val_loss: 131.1168\n",
      "Epoch 21/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 152.6339 - val_loss: 128.3203\n",
      "Epoch 22/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 148.7234 - val_loss: 130.2534\n",
      "Epoch 23/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 145.5402 - val_loss: 129.4397\n",
      "Epoch 24/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 135.7922 - val_loss: 129.8118\n",
      "Epoch 25/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 150.5170 - val_loss: 129.8889\n",
      "Epoch 26/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 149.7286 - val_loss: 129.3611\n",
      "Epoch 27/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 141.2022 - val_loss: 129.4820\n",
      "Epoch 28/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130.6887 - val_loss: 130.1821\n",
      "Epoch 29/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 138.5835 - val_loss: 131.3409\n",
      "Epoch 30/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130.6021 - val_loss: 130.5458\n",
      "Epoch 31/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 134.1189 - val_loss: 132.6194\n",
      "Epoch 32/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 123.3340 - val_loss: 130.7775\n",
      "Epoch 33/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.5918 - val_loss: 132.0156\n",
      "Epoch 34/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 129.8525 - val_loss: 131.4014\n",
      "Epoch 35/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.9080 - val_loss: 131.0873\n",
      "Epoch 36/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 124.5241 - val_loss: 132.9740\n",
      "Epoch 37/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 130.8071 - val_loss: 134.3550\n",
      "Epoch 38/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.8082 - val_loss: 133.4201\n",
      "Epoch 39/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.3981 - val_loss: 134.4538\n",
      "Epoch 40/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.1510 - val_loss: 133.1513\n",
      "Epoch 41/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.4923 - val_loss: 133.8058\n",
      "Epoch 42/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.5349 - val_loss: 134.2379\n",
      "Epoch 43/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 126.0279 - val_loss: 135.7137\n",
      "Epoch 44/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.1284 - val_loss: 135.7472\n",
      "Epoch 45/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 105.4043 - val_loss: 133.7604\n",
      "Epoch 46/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 104.7206 - val_loss: 136.1331\n",
      "Epoch 47/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.0052 - val_loss: 134.9016\n",
      "Epoch 48/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 103.2600 - val_loss: 135.7565\n",
      "Epoch 49/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 106.7399 - val_loss: 132.0536\n",
      "Epoch 50/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.6985 - val_loss: 137.5715\n",
      "Epoch 51/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 104.1708 - val_loss: 132.2793\n",
      "Epoch 52/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 100.9782 - val_loss: 133.0044\n",
      "Epoch 53/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 98.5523 - val_loss: 138.1403\n",
      "Epoch 54/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 103.3367 - val_loss: 133.3109\n",
      "Epoch 55/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 83.4230 - val_loss: 132.2963\n",
      "Epoch 56/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 86.4642 - val_loss: 132.2378\n",
      "Epoch 57/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 84.2701 - val_loss: 130.2583\n",
      "Epoch 58/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 74.5523 - val_loss: 128.6197\n",
      "Epoch 59/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 75.4420 - val_loss: 125.4682\n",
      "Epoch 60/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 69.3879 - val_loss: 123.9881\n",
      "Epoch 61/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 70.0054 - val_loss: 123.4364\n",
      "Epoch 62/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 66.9790 - val_loss: 121.9157\n",
      "Epoch 63/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 66.8084 - val_loss: 122.8659\n",
      "Epoch 64/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.3588 - val_loss: 120.0312\n",
      "Epoch 65/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.8269 - val_loss: 121.9333\n",
      "Epoch 66/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 57.8592 - val_loss: 117.4409\n",
      "Epoch 67/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 58.8995 - val_loss: 121.3135\n",
      "Epoch 68/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.8529 - val_loss: 114.6825\n",
      "Epoch 69/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 53.3959 - val_loss: 116.2079\n",
      "Epoch 70/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.6569 - val_loss: 117.2713\n",
      "Epoch 71/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 48.2137 - val_loss: 119.2338\n",
      "Epoch 72/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.0850 - val_loss: 119.1463\n",
      "Epoch 73/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 46.0588 - val_loss: 116.1992\n",
      "Epoch 74/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 49.1901 - val_loss: 110.1990\n",
      "Epoch 75/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.2832 - val_loss: 117.8570\n",
      "Epoch 76/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 42.4317 - val_loss: 117.5675\n",
      "Epoch 77/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 40.3086 - val_loss: 117.0521\n",
      "Epoch 78/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 39.6542 - val_loss: 118.4698\n",
      "Epoch 79/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.5985 - val_loss: 114.3519\n",
      "Epoch 80/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 38.6835 - val_loss: 116.2491\n",
      "Epoch 81/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.0051 - val_loss: 123.6484\n",
      "Epoch 82/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 37.8484 - val_loss: 119.0191\n",
      "Epoch 83/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.7729 - val_loss: 127.9340\n",
      "Epoch 84/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 36.2682 - val_loss: 129.5387\n",
      "Epoch 85/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.7152 - val_loss: 118.2893\n",
      "Epoch 86/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.4778 - val_loss: 117.5515\n",
      "Epoch 87/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.3405 - val_loss: 126.0370\n",
      "Epoch 88/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.3794 - val_loss: 120.1780\n",
      "Epoch 89/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 35.2570 - val_loss: 126.4521\n",
      "Epoch 90/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.2437 - val_loss: 123.3062\n",
      "Epoch 91/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 33.5923 - val_loss: 129.2004\n",
      "Epoch 92/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.8744 - val_loss: 121.5969\n",
      "Epoch 93/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.9059 - val_loss: 133.7439\n",
      "Epoch 94/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5496 - val_loss: 125.0613\n",
      "Epoch 95/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 29.9540 - val_loss: 131.5864\n",
      "Epoch 96/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.1272 - val_loss: 127.0323\n",
      "Epoch 97/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.2943 - val_loss: 127.4584\n",
      "Epoch 98/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.3829 - val_loss: 131.8278\n",
      "Epoch 99/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.5881 - val_loss: 126.3613\n",
      "Epoch 100/100\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 30.5241 - val_loss: 132.5546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x224e4a72d10>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training & testing the NN\n",
    "model = regression_model()\n",
    "\n",
    "model.fit(predictors_norm, target, validation_split=.3, epochs=100,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02177</td>\n",
       "      <td>82.5</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>7.610</td>\n",
       "      <td>15.7</td>\n",
       "      <td>6.2700</td>\n",
       "      <td>2.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.38</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.89822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.631</td>\n",
       "      <td>4.970</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.3325</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>375.52</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>6.037</td>\n",
       "      <td>34.5</td>\n",
       "      <td>5.9853</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4   ...    8      9     10      11     12\n",
       "0  1.23247   0.0   8.14  0.0  0.538  ...   4.0  307.0  21.0  396.90  18.72\n",
       "1  0.02177  82.5   2.03  0.0  0.415  ...   2.0  348.0  14.7  395.38   3.11\n",
       "2  4.89822   0.0  18.10  0.0  0.631  ...  24.0  666.0  20.2  375.52   3.26\n",
       "3  0.03961   0.0   5.19  0.0  0.515  ...   5.0  224.0  20.2  396.90   8.01\n",
       "4  3.69311   0.0  18.10  0.0  0.713  ...  24.0  666.0  20.2  391.43  14.65\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_df = pd.DataFrame(train_data)\n",
    "train_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing --> large values would dominate w/o normalization\n",
    "# feature-wise normalization\n",
    "mean = train_data.mean(axis=0) # column wise\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "# centralizing test data\n",
    "test_data -= mean\n",
    "test_data /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build NN\n",
    "def regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu', input_shape=(train_data.shape[1])))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='mse',\n",
    "                  metrics = ['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.4 Validating your approach using K-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. split into test, training, validation --> model. evaluate --> MAE_1, MAE_2, MAE3 -->$\\mu_{MAE}^{(1)}$\n",
    "2. shuffle the data again --> MAE_1, MAE_2, MAE_3 --> $\\mu_{MAE}^{(2)}$\n",
    "3. --> $\\bar{\\mu}$\n",
    "\n",
    "Leave-one-out c.v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
